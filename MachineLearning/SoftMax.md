# SoftMax

SoftMax是用来计算模型的损失函数的

`Li =-log(exp(yi)/∑exp(yi))`

它的设计思路是这样的，

* 先通过模型，输入样本之后，它会对于每一个分类计算出一个具体的值

* 对每个类别所得到的值，分别作为e的幂指数，将数值进行放大，拉大差异

* 然后通过取对数相反数的方式来获取损失函数。

这种方式在(模型结果取到任何值的情况下)都可以取到对应的取到的损失；而SVM损失函数在某些情况下(比如某种错误类型取到的值与真实类型取到的值相近的情况下)算出来的损失可能为0.

从我们输入x到我们计算出它的SoftMax损失函数的过程，叫做**前向传播**

**反向传播**：优化权重参数

* Bachsize:通常是2的整数倍。一次迭代
* epoch:例如：对于一个训练集，里面共有4000张图片,一个epoch表示将所有的4000张图片都跑一遍。
