---
title: 统计学习方法第一章
tags:  统计学习,  概念
grammar_cjkRuby: true
---
## 基本概念

### **统计学习**，即机器学习：是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。
#### 特点：
* 统计学习以计算机及网络为平台，是建立在计算机及网络之上的

* 统计学习以数据为研究对象，是数据驱动的学科

* 统计学习的目的是对数据进行预测与分析

* 统计学习以方法为中心，统计学习方法构建模型并应用模型进行预测与分析
#### 前提：统计学习关于数据的基本假设是同类数据具有一定的统计规律性
#### 目的：用于对数据进行预测与分析，特别是对未知新数据进行预测与分析
#### 目标：虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析
#### 组成：`监督学习（supervised learning）`、`非监督学习（unsupervised learning）`、`半监督学习（semi-supervised learning）`和`强化学习（reinforcement learning）`等组成。
#### 三要素：模型的假设空间、模型选择的准则以及模型学习的算法
统计学习研究一般包括统计学习方法（statistical learning method）、统计学习理论（statistical learning theory）及统计学习应用（application of statistical learning）三个方面

#### 监督学习（supervised learning）的任务是学习一个模型，使模型能够对任意给定的输入，对其相应的输出做出一个好的预测
输入空间的一个实例被称为特征向量，特征向量在一起构成的特征空间的每一个维度代表了输入信息的一个特征

#### 回归的问题：在监督学习中，输入变量与输出变量均为连续变量
#### 分类的问题：在监督学习中，输出变量为有限个离散变量
#### 标注的问题
***

> 监督学习假设输入与输出的随机变量X和Y遵循联合概率分布P(X,Y)。训练数据与测试数据被看作是依联合概率分布P(X,Y)独立同分布产生的。

***

## 统计学习方法由统计学习三要素组成，即**模型**、**策略**与**算法**。


#### 损失函数：损失函数用于度量模型一次预测的好坏。
#### 风险函数：风险函数用于度量平均意义下模型预测的好坏。

#### 经验风险函数：模型f(X)关于训练数据集的平均损失称为经验风险，在假设空间、损失函数以及训练数据集确定的情况下，经验风险函数式就可以确定。
#### 策略：经验风险最小化与结构风险最小化

#### 经验风险：平均损失

> 极大似然估计其实就是经验风险最小化的一个例子，因为在极大似然估计下，假设空间、损失函数以及训练数据集是确定的

#### 结构风险：在经验风险最小化的基础上增加了表示模型复杂度的正则化项或者罚项

* 经验风险最小化在数据量较小的情况下容易发生过拟合的现象
* 结构风险最小化就是为了避免过拟合现象，其等价于正则化，在经验风险最小化的基础上增加了表示模型复杂度的正则化项或者罚项。

## 模型的选择

#### 正则化：模型选择的典型方法，是结构风险最小化的实现。化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。

>正则化项一般具有以下形式：
>![enter description here][1]
>第一项是经验风险，第二项是正则化项，λ≧0为调整两者之间关系的系数。


#### 交叉验证：一种常用的模型选择的方法。
如果给定的样本数据充足，进行模型选择的一种简单方法是随机地将数据集切分成三部分，分别为**训练集**（training set）、**验证集**（validation set）和**测试集**（test set）。

> 训练集用来训练模型，
> 验证集用于模型的选择，
> 而测试集用于最终对学习方法的评估。

如果数据是不充足的。为了选择好的模型，可以采用交叉验证方法。交叉验证的基本想法是**重复**地使用数据；把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复地进行训练、测试以及模型选择

* #### 简单交叉验证
简单交叉验证方法是：首先随机地将已给数据分为两部分，一部分作为训练集，另一部分作为测试集（例如，70%的数据为训练集，30%的数据为测试集）；然后用训练集在各种条件下（例如，不同的参数个数）训练模型，从而得到不同的模型；在测试集上评价各个模型的测试误差，选出测试误差最小的模型。
* #### S折交叉验证
应用最多的是S折交叉验证（S-fold cross validation），方法如下：首先随机地将已给数据切分为S个互不相交的大小相同的子集；然后利用S-1个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的S种选择重复进行；最后选出S次评测中平均测试误差最小的模型。
* ####留一交叉验证
S折交叉验证的特殊情形是S＝N，称为留一交叉验证（leave-one-out cross validation），往往在数据缺乏的情况下使用。这里，N是给定数据集的容量

#### 泛化能力：学习方法对未知数据的预测能力
>现实中采用最多的办法是通过测试误差来评价学习方法的泛化能力。这种评价有点依赖测试数据集的好坏。

#### 泛化误差上届的性质：
* 它是样本容量的函数，当样本容量增加时，泛化上届趋于0
* 它是假设空间容量的函数，假设空间容量越大，模型就越难学，泛化误差上届就越大


#### 过拟合：是指学习时选择的模型所包含的参数过多，以致于出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。、



### 监督学习方法又分为：生成方法和判别方法

* 生成方法 --> 生成模型

>由数据学习联合概率分布P(X,Y)，然后求出条件概率分布P(Y|X)作为预测的模型，即生成模型
>生成方法可以还原出联合给吕分布P(X,Y)，学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型，当存在`隐变量`的时候仍然可以使用生成方法。

* 判别方法 -->判别模型

>由数据直接学习决策函数f(X)或者条件概率分布P(Y|X)作为预测的模型，即判别模型
>判别方法直接学习的是条件概率P(Y|X)或者决策函数f(X)，直接面对预测，往往学习的准确率更高。


### 标注问题
>标注问题可以理解为分类问题的一个推广，标注问题又是更复杂的结构预测问题的简单形式。

* 输入：一个观测序列

* 输出：一个标记序列或状态序列

* 目标：学习一个模型，使它能够对观测序列给出标记序列作为预测

* 评价指标：标注准确率、精确率和召回率

* 常用的统计学习方法有：隐马尔可夫模型，条件随机场。


### 回归问题
>用于预测输入变量和输出变量之间的关系，特别是输入变量的值发生变化时，输出变量的值随之发生的变化。
>回归模型正是表示从输入变量到输出变量之间映射的函数。
>回归问题的学习等价于函数拟合：选择一条合适的曲线使其很好地拟合已知数据且很好地预测未知数据。

* 损失函数：最常用到的损失函数是平方损失函数。这种情况下，回归问题可由**最小二乘法**来解决

* 分类：
          1.按照输入变量的个数，可以分为一元回归和多元回归
          2.按照输入变量和输出变量之间关系的类型即模型的类型，可分为线性回归和非线性回归。
  [1]: ./images/1567416178565.jpg "1567416178565.jpg"
