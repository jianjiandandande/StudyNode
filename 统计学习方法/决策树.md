---
title: 决策树
tags: 信息增益,信息增益率,熵
---

#### 决策树学习的3个步骤
* 特征选择

* 决策树的生成

* 决策树的剪枝

#### 决策树的定义
分类决策树模型是一种描述对实例进行分类的树形结构。决策树由**结点**，**有向边**组成。结点有两种类型：**内部结点**和**叶结点**。内部结点表示一个**特征或属性**，叶结点表示一个**类**。

#### 决策树学习的规则
从根节点开始，对实例的某一特征进行测试，根据测试结果，将实例分配到其子节点；这时，每一个子结点对应着该特征的一个取值，如此递归地对实例进行测试并分配，直至达到叶结点。最后将实例分到叶结点的类中。

#### 决策树与条件概率分布

决策树还表示给定**特征条件**下的**条件概率分布**。这一条件概率分布定义在特征空间的一个**划分**上。将特征空间划分为互不相交的单元或区域，并在每个单元定义一个**类的概率分布**就构成了一个条件概率分布。**决策树的一条路径对应于划分中的一个单元**。决策树表示的条件概率分布由各个单元给定条件下类的条件概率分布组成。

#### 局部最优和全局最优

* 局部最优：决策树的生成

* 全局最优：决策树的剪枝

#### 信息增益

##### 一、熵
*  在信息论与概率统计中，熵是表示**随机变量不确定性**的度量。熵只依赖于X的分布，而与X的取值无关。熵越大，随机变量的不确定性越大。

* 在默认情况下，没有分类的情况下，事物本身的混乱程度，即它的熵值为H0, 根据某一个属性值对他进行分类后，事物此时的熵H1相对于上一次没有分类时的H0有所下降，也就是**分类提高了事物的纯度，混乱度下降**，即分类使得实例对应的熵有所下降。

##### 二、条件熵
* 普通条件熵：条件熵H(Y|X)表示在已知随机变量X的条件下随机变量Y的不确定性。

* 随机变量X给定条件下Y的条件熵：X给定条件下Y的条件概率分布的熵对X的数学期望。

##### 三、经验熵与经验条件熵
当熵和条件熵中的概率由数据局估计（特别是极大似然估计）得到时，所对应的熵与条件熵分别称为经验熵和经验条件熵。

##### 四、信息增益
表示得知特征X的信息而使得类Y的信息的不确定性减少的程度。